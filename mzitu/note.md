[TOC]

# 思路整理
## 1.获取所有的详情页面链接
通过访问首页目录图[从初始页搜索，不停获取下一个页面的链接，直到没有下一页为止],将获取到详情链接存储到数据库中

## 2.依次访问urls里的链接，获取每个详情页里面的图片并下载
- 建一个`mzitu_yet_urls`存储下载过的链接【主要是为了应对下载中断的问题】
- 每次下载前,查询当前url是否已存在`mzitu_yet_urls`中，如果已存在则请求下一条url
- 每当下载成功将当前url存储到`mzitu_yet_urls`中
- 请求完页面最后urls后，停止程序

# 一些问题
错误的页面有没有被保存到`mzitu_yet_urls`,理论上应该是没有的。

有一部分页面报错了，这部分页面再次执行时可以得到解决吗？

存在缺陷：无法得知有多少页面是报错的，关于有没有页面报错这一信息有所缺失